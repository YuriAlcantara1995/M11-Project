{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import init\n",
    "from torch.nn.modules import loss\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder('Dataset/train', transform = transforms.ToTensor())\n",
    "test_dataset = datasets.ImageFolder('Dataset/test', transform = transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 501\n",
       "    Root location: Dataset/train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset ImageFolder\n",
       "    Number of datapoints: 125\n",
       "    Root location: Dataset/test\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /home/yuri/.local/lib/python3.8/site-packages (3.5.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/yuri/.local/lib/python3.8/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/yuri/.local/lib/python3.8/site-packages (from matplotlib) (4.33.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/yuri/.local/lib/python3.8/site-packages (from matplotlib) (1.22.4)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/yuri/.local/lib/python3.8/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/yuri/.local/lib/python3.8/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/yuri/.local/lib/python3.8/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/lib/python3/dist-packages (from matplotlib) (2.7.3)\n",
      "\u001b[33mWARNING: There was an error checking the latest version of pip.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "toPIL = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def example(i):\n",
    "    print(train_dataset[i][1])\n",
    "    return toPIL(train_dataset[i][0]).resize((256, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256 at 0x7F24468FD8E0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 1, 1, 0, 0, 0, 2, 0, 1, 0, 1, 2, 1, 0, 1, 0, 2, 1, 1, 1, 1, 2, 2,\n",
       "        1, 0, 1, 0, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__iter__().__next__()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 3, 254, 254])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.__iter__().__next__()[0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss_function, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 5 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader, loss_function):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += loss_function(output, target).sum().item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    return 100. * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/501 (0%)]\tLoss: 1.290470\n",
      "Train Epoch: 0 [160/501 (31%)]\tLoss: 0.879520\n",
      "Train Epoch: 0 [320/501 (62%)]\tLoss: 0.737403\n",
      "Train Epoch: 0 [315/501 (94%)]\tLoss: 0.412995\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 81/125 (65%)\n",
      "\n",
      "Train Epoch: 1 [0/501 (0%)]\tLoss: 0.510599\n",
      "Train Epoch: 1 [160/501 (31%)]\tLoss: 0.319032\n",
      "Train Epoch: 1 [320/501 (62%)]\tLoss: 0.422188\n",
      "Train Epoch: 1 [315/501 (94%)]\tLoss: 0.463822\n",
      "\n",
      "Test set: Average loss: 0.0189, Accuracy: 104/125 (83%)\n",
      "\n",
      "Train Epoch: 2 [0/501 (0%)]\tLoss: 0.394420\n",
      "Train Epoch: 2 [160/501 (31%)]\tLoss: 0.368418\n",
      "Train Epoch: 2 [320/501 (62%)]\tLoss: 0.353466\n",
      "Train Epoch: 2 [315/501 (94%)]\tLoss: 0.367363\n",
      "\n",
      "Test set: Average loss: 0.0173, Accuracy: 99/125 (79%)\n",
      "\n",
      "Train Epoch: 3 [0/501 (0%)]\tLoss: 0.283121\n",
      "Train Epoch: 3 [160/501 (31%)]\tLoss: 0.268302\n",
      "Train Epoch: 3 [320/501 (62%)]\tLoss: 0.326449\n",
      "Train Epoch: 3 [315/501 (94%)]\tLoss: 0.274672\n",
      "\n",
      "Test set: Average loss: 0.0152, Accuracy: 106/125 (85%)\n",
      "\n",
      "Train Epoch: 4 [0/501 (0%)]\tLoss: 0.285316\n",
      "Train Epoch: 4 [160/501 (31%)]\tLoss: 0.299107\n",
      "Train Epoch: 4 [320/501 (62%)]\tLoss: 0.335810\n",
      "Train Epoch: 4 [315/501 (94%)]\tLoss: 0.316298\n",
      "\n",
      "Test set: Average loss: 0.0151, Accuracy: 107/125 (86%)\n",
      "\n",
      "Train Epoch: 5 [0/501 (0%)]\tLoss: 0.275705\n",
      "Train Epoch: 5 [160/501 (31%)]\tLoss: 0.285203\n",
      "Train Epoch: 5 [320/501 (62%)]\tLoss: 0.382710\n",
      "Train Epoch: 5 [315/501 (94%)]\tLoss: 0.290994\n",
      "\n",
      "Test set: Average loss: 0.0140, Accuracy: 107/125 (86%)\n",
      "\n",
      "Train Epoch: 6 [0/501 (0%)]\tLoss: 0.249816\n",
      "Train Epoch: 6 [160/501 (31%)]\tLoss: 0.264670\n",
      "Train Epoch: 6 [320/501 (62%)]\tLoss: 0.257952\n",
      "Train Epoch: 6 [315/501 (94%)]\tLoss: 0.442286\n",
      "\n",
      "Test set: Average loss: 0.0206, Accuracy: 89/125 (71%)\n",
      "\n",
      "Train Epoch: 7 [0/501 (0%)]\tLoss: 0.374912\n",
      "Train Epoch: 7 [160/501 (31%)]\tLoss: 0.208754\n",
      "Train Epoch: 7 [320/501 (62%)]\tLoss: 0.272598\n",
      "Train Epoch: 7 [315/501 (94%)]\tLoss: 0.265284\n",
      "\n",
      "Test set: Average loss: 0.0216, Accuracy: 91/125 (73%)\n",
      "\n",
      "Train Epoch: 8 [0/501 (0%)]\tLoss: 0.258022\n",
      "Train Epoch: 8 [160/501 (31%)]\tLoss: 0.227456\n",
      "Train Epoch: 8 [320/501 (62%)]\tLoss: 0.219279\n",
      "Train Epoch: 8 [315/501 (94%)]\tLoss: 0.208236\n",
      "\n",
      "Test set: Average loss: 0.0115, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 9 [0/501 (0%)]\tLoss: 0.213721\n",
      "Train Epoch: 9 [160/501 (31%)]\tLoss: 0.194604\n",
      "Train Epoch: 9 [320/501 (62%)]\tLoss: 0.203770\n",
      "Train Epoch: 9 [315/501 (94%)]\tLoss: 0.291482\n",
      "\n",
      "Test set: Average loss: 0.0126, Accuracy: 112/125 (90%)\n",
      "\n",
      "Train Epoch: 10 [0/501 (0%)]\tLoss: 0.235588\n",
      "Train Epoch: 10 [160/501 (31%)]\tLoss: 0.219538\n",
      "Train Epoch: 10 [320/501 (62%)]\tLoss: 0.180783\n",
      "Train Epoch: 10 [315/501 (94%)]\tLoss: 0.266513\n",
      "\n",
      "Test set: Average loss: 0.0117, Accuracy: 113/125 (90%)\n",
      "\n",
      "Train Epoch: 11 [0/501 (0%)]\tLoss: 0.183849\n",
      "Train Epoch: 11 [160/501 (31%)]\tLoss: 0.186090\n",
      "Train Epoch: 11 [320/501 (62%)]\tLoss: 0.297631\n",
      "Train Epoch: 11 [315/501 (94%)]\tLoss: 0.204877\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 12 [0/501 (0%)]\tLoss: 0.180844\n",
      "Train Epoch: 12 [160/501 (31%)]\tLoss: 0.185486\n",
      "Train Epoch: 12 [320/501 (62%)]\tLoss: 0.185951\n",
      "Train Epoch: 12 [315/501 (94%)]\tLoss: 0.340130\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 104/125 (83%)\n",
      "\n",
      "Train Epoch: 13 [0/501 (0%)]\tLoss: 0.204756\n",
      "Train Epoch: 13 [160/501 (31%)]\tLoss: 0.212945\n",
      "Train Epoch: 13 [320/501 (62%)]\tLoss: 0.182367\n",
      "Train Epoch: 13 [315/501 (94%)]\tLoss: 0.170287\n",
      "\n",
      "Test set: Average loss: 0.0116, Accuracy: 113/125 (90%)\n",
      "\n",
      "Train Epoch: 14 [0/501 (0%)]\tLoss: 0.154879\n",
      "Train Epoch: 14 [160/501 (31%)]\tLoss: 0.167119\n",
      "Train Epoch: 14 [320/501 (62%)]\tLoss: 0.166315\n",
      "Train Epoch: 14 [315/501 (94%)]\tLoss: 0.234720\n",
      "\n",
      "Test set: Average loss: 0.0122, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 15 [0/501 (0%)]\tLoss: 0.186533\n",
      "Train Epoch: 15 [160/501 (31%)]\tLoss: 0.188346\n",
      "Train Epoch: 15 [320/501 (62%)]\tLoss: 0.178564\n",
      "Train Epoch: 15 [315/501 (94%)]\tLoss: 0.183118\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 105/125 (84%)\n",
      "\n",
      "Train Epoch: 16 [0/501 (0%)]\tLoss: 0.170695\n",
      "Train Epoch: 16 [160/501 (31%)]\tLoss: 0.149351\n",
      "Train Epoch: 16 [320/501 (62%)]\tLoss: 0.144418\n",
      "Train Epoch: 16 [315/501 (94%)]\tLoss: 0.283899\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 113/125 (90%)\n",
      "\n",
      "Train Epoch: 17 [0/501 (0%)]\tLoss: 0.163168\n",
      "Train Epoch: 17 [160/501 (31%)]\tLoss: 0.261586\n",
      "Train Epoch: 17 [320/501 (62%)]\tLoss: 0.207406\n",
      "Train Epoch: 17 [315/501 (94%)]\tLoss: 0.231337\n",
      "\n",
      "Test set: Average loss: 0.0102, Accuracy: 116/125 (93%)\n",
      "\n",
      "Train Epoch: 18 [0/501 (0%)]\tLoss: 0.168250\n",
      "Train Epoch: 18 [160/501 (31%)]\tLoss: 0.159973\n",
      "Train Epoch: 18 [320/501 (62%)]\tLoss: 0.162107\n",
      "Train Epoch: 18 [315/501 (94%)]\tLoss: 0.177942\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 109/125 (87%)\n",
      "\n",
      "Train Epoch: 19 [0/501 (0%)]\tLoss: 0.170154\n",
      "Train Epoch: 19 [160/501 (31%)]\tLoss: 0.150638\n",
      "Train Epoch: 19 [320/501 (62%)]\tLoss: 0.139335\n",
      "Train Epoch: 19 [315/501 (94%)]\tLoss: 0.152048\n",
      "\n",
      "Test set: Average loss: 0.0103, Accuracy: 115/125 (92%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_batchnorm = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(193548, 512), \n",
    "                      nn.BatchNorm1d(512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(512, 256), \n",
    "                      nn.BatchNorm1d(256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(256, 64), \n",
    "                      nn.BatchNorm1d(64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(64, 3),\n",
    "                      nn.BatchNorm1d(3))\n",
    "optimizer = optim.SGD(model_batchnorm.parameters(), lr=0.01)\n",
    "loss_function = loss.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(20):\n",
    "        train(model_batchnorm, train_loader, optimizer, loss_function, epoch)\n",
    "        test(model_batchnorm, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/501 (0%)]\tLoss: 1.442661\n",
      "Train Epoch: 0 [160/501 (31%)]\tLoss: 0.787907\n",
      "Train Epoch: 0 [320/501 (62%)]\tLoss: 0.795146\n",
      "Train Epoch: 0 [315/501 (94%)]\tLoss: 0.627036\n",
      "\n",
      "Test set: Average loss: 0.0256, Accuracy: 82/125 (66%)\n",
      "\n",
      "Train Epoch: 1 [0/501 (0%)]\tLoss: 0.629832\n",
      "Train Epoch: 1 [160/501 (31%)]\tLoss: 0.567743\n",
      "Train Epoch: 1 [320/501 (62%)]\tLoss: 0.651833\n",
      "Train Epoch: 1 [315/501 (94%)]\tLoss: 0.777818\n",
      "\n",
      "Test set: Average loss: 0.0217, Accuracy: 79/125 (63%)\n",
      "\n",
      "Train Epoch: 2 [0/501 (0%)]\tLoss: 0.656914\n",
      "Train Epoch: 2 [160/501 (31%)]\tLoss: 0.747171\n",
      "Train Epoch: 2 [320/501 (62%)]\tLoss: 0.536830\n",
      "Train Epoch: 2 [315/501 (94%)]\tLoss: 0.517003\n",
      "\n",
      "Test set: Average loss: 0.0166, Accuracy: 107/125 (86%)\n",
      "\n",
      "Train Epoch: 3 [0/501 (0%)]\tLoss: 0.566710\n",
      "Train Epoch: 3 [160/501 (31%)]\tLoss: 0.514399\n",
      "Train Epoch: 3 [320/501 (62%)]\tLoss: 0.511275\n",
      "Train Epoch: 3 [315/501 (94%)]\tLoss: 0.676070\n",
      "\n",
      "Test set: Average loss: 0.0168, Accuracy: 108/125 (86%)\n",
      "\n",
      "Train Epoch: 4 [0/501 (0%)]\tLoss: 0.404628\n",
      "Train Epoch: 4 [160/501 (31%)]\tLoss: 0.473457\n",
      "Train Epoch: 4 [320/501 (62%)]\tLoss: 0.545868\n",
      "Train Epoch: 4 [315/501 (94%)]\tLoss: 0.538490\n",
      "\n",
      "Test set: Average loss: 0.0158, Accuracy: 111/125 (89%)\n",
      "\n",
      "Train Epoch: 5 [0/501 (0%)]\tLoss: 0.439079\n",
      "Train Epoch: 5 [160/501 (31%)]\tLoss: 0.486489\n",
      "Train Epoch: 5 [320/501 (62%)]\tLoss: 0.648188\n",
      "Train Epoch: 5 [315/501 (94%)]\tLoss: 0.442608\n",
      "\n",
      "Test set: Average loss: 0.0139, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 6 [0/501 (0%)]\tLoss: 0.511326\n",
      "Train Epoch: 6 [160/501 (31%)]\tLoss: 0.348489\n",
      "Train Epoch: 6 [320/501 (62%)]\tLoss: 0.481642\n",
      "Train Epoch: 6 [315/501 (94%)]\tLoss: 0.335825\n",
      "\n",
      "Test set: Average loss: 0.0137, Accuracy: 115/125 (92%)\n",
      "\n",
      "Train Epoch: 7 [0/501 (0%)]\tLoss: 0.537374\n",
      "Train Epoch: 7 [160/501 (31%)]\tLoss: 0.370902\n",
      "Train Epoch: 7 [320/501 (62%)]\tLoss: 0.397084\n",
      "Train Epoch: 7 [315/501 (94%)]\tLoss: 0.519042\n",
      "\n",
      "Test set: Average loss: 0.0134, Accuracy: 113/125 (90%)\n",
      "\n",
      "Train Epoch: 8 [0/501 (0%)]\tLoss: 0.477875\n",
      "Train Epoch: 8 [160/501 (31%)]\tLoss: 0.490886\n",
      "Train Epoch: 8 [320/501 (62%)]\tLoss: 0.481145\n",
      "Train Epoch: 8 [315/501 (94%)]\tLoss: 0.534952\n",
      "\n",
      "Test set: Average loss: 0.0148, Accuracy: 107/125 (86%)\n",
      "\n",
      "Train Epoch: 9 [0/501 (0%)]\tLoss: 0.325453\n",
      "Train Epoch: 9 [160/501 (31%)]\tLoss: 0.364487\n",
      "Train Epoch: 9 [320/501 (62%)]\tLoss: 0.393594\n",
      "Train Epoch: 9 [315/501 (94%)]\tLoss: 0.575647\n",
      "\n",
      "Test set: Average loss: 0.0131, Accuracy: 112/125 (90%)\n",
      "\n",
      "Train Epoch: 10 [0/501 (0%)]\tLoss: 0.421756\n",
      "Train Epoch: 10 [160/501 (31%)]\tLoss: 0.364210\n",
      "Train Epoch: 10 [320/501 (62%)]\tLoss: 0.519301\n",
      "Train Epoch: 10 [315/501 (94%)]\tLoss: 0.336578\n",
      "\n",
      "Test set: Average loss: 0.0129, Accuracy: 115/125 (92%)\n",
      "\n",
      "Train Epoch: 11 [0/501 (0%)]\tLoss: 0.375607\n",
      "Train Epoch: 11 [160/501 (31%)]\tLoss: 0.541059\n",
      "Train Epoch: 11 [320/501 (62%)]\tLoss: 0.421686\n",
      "Train Epoch: 11 [315/501 (94%)]\tLoss: 0.327436\n",
      "\n",
      "Test set: Average loss: 0.0141, Accuracy: 106/125 (85%)\n",
      "\n",
      "Train Epoch: 12 [0/501 (0%)]\tLoss: 0.343084\n",
      "Train Epoch: 12 [160/501 (31%)]\tLoss: 0.449353\n",
      "Train Epoch: 12 [320/501 (62%)]\tLoss: 0.344862\n",
      "Train Epoch: 12 [315/501 (94%)]\tLoss: 0.379050\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 13 [0/501 (0%)]\tLoss: 0.339571\n",
      "Train Epoch: 13 [160/501 (31%)]\tLoss: 0.275194\n",
      "Train Epoch: 13 [320/501 (62%)]\tLoss: 0.372910\n",
      "Train Epoch: 13 [315/501 (94%)]\tLoss: 0.247809\n",
      "\n",
      "Test set: Average loss: 0.0123, Accuracy: 115/125 (92%)\n",
      "\n",
      "Train Epoch: 14 [0/501 (0%)]\tLoss: 0.320508\n",
      "Train Epoch: 14 [160/501 (31%)]\tLoss: 0.290568\n",
      "Train Epoch: 14 [320/501 (62%)]\tLoss: 0.331863\n",
      "Train Epoch: 14 [315/501 (94%)]\tLoss: 0.463078\n",
      "\n",
      "Test set: Average loss: 0.0119, Accuracy: 117/125 (94%)\n",
      "\n",
      "Train Epoch: 15 [0/501 (0%)]\tLoss: 0.349172\n",
      "Train Epoch: 15 [160/501 (31%)]\tLoss: 0.370447\n",
      "Train Epoch: 15 [320/501 (62%)]\tLoss: 0.278702\n",
      "Train Epoch: 15 [315/501 (94%)]\tLoss: 0.546683\n",
      "\n",
      "Test set: Average loss: 0.0108, Accuracy: 115/125 (92%)\n",
      "\n",
      "Train Epoch: 16 [0/501 (0%)]\tLoss: 0.345637\n",
      "Train Epoch: 16 [160/501 (31%)]\tLoss: 0.339856\n",
      "Train Epoch: 16 [320/501 (62%)]\tLoss: 0.302894\n",
      "Train Epoch: 16 [315/501 (94%)]\tLoss: 0.391895\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 17 [0/501 (0%)]\tLoss: 0.290608\n",
      "Train Epoch: 17 [160/501 (31%)]\tLoss: 0.433425\n",
      "Train Epoch: 17 [320/501 (62%)]\tLoss: 0.308295\n",
      "Train Epoch: 17 [315/501 (94%)]\tLoss: 0.209738\n",
      "\n",
      "Test set: Average loss: 0.0114, Accuracy: 115/125 (92%)\n",
      "\n",
      "Train Epoch: 18 [0/501 (0%)]\tLoss: 0.308881\n",
      "Train Epoch: 18 [160/501 (31%)]\tLoss: 0.271119\n",
      "Train Epoch: 18 [320/501 (62%)]\tLoss: 0.345664\n",
      "Train Epoch: 18 [315/501 (94%)]\tLoss: 0.278741\n",
      "\n",
      "Test set: Average loss: 0.0112, Accuracy: 114/125 (91%)\n",
      "\n",
      "Train Epoch: 19 [0/501 (0%)]\tLoss: 0.239305\n",
      "Train Epoch: 19 [160/501 (31%)]\tLoss: 0.273394\n",
      "Train Epoch: 19 [320/501 (62%)]\tLoss: 0.389277\n",
      "Train Epoch: 19 [315/501 (94%)]\tLoss: 0.276191\n",
      "\n",
      "Test set: Average loss: 0.0109, Accuracy: 113/125 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_dropout = nn.Sequential(nn.Flatten(),\n",
    "                      nn.Linear(193548, 512), \n",
    "                      nn.BatchNorm1d(512),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(512, 256), \n",
    "                      nn.BatchNorm1d(256),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.3),\n",
    "                      nn.Linear(256, 64), \n",
    "                      nn.BatchNorm1d(64),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Dropout(0.2),\n",
    "                      nn.Linear(64, 3),\n",
    "                      nn.BatchNorm1d(3))\n",
    "optimizer = optim.SGD(model_dropout.parameters(), lr=0.01)\n",
    "loss_function = loss.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "for epoch in range(20):\n",
    "        train(model_dropout, train_loader, optimizer, loss_function, epoch)\n",
    "        test(model_dropout, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = nn.Sequential(\n",
    "                      nn.Conv2d(3, 48, 7, bias=False),\n",
    "                      nn.BatchNorm2d(48), \n",
    "                      nn.Conv2d(48, 96, 7, bias=False),\n",
    "                      nn.BatchNorm2d(96), \n",
    "                      nn.Linear(242, 3, bias=False),\n",
    "                      nn.BatchNorm1d(3))\n",
    "optimizer = optim.Adam(model_cnn.parameters(), lr=0.001)\n",
    "loss_function = loss.CrossEntropyLoss()\n",
    "    \n",
    "\n",
    "for epoch in range(20):\n",
    "        train(model_cnn, train_loader, optimizer, loss_function, epoch)\n",
    "        test(model_cnn, test_loader, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
